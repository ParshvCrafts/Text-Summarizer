# Text Summarizer - Environment Configuration
# =============================================
# Copy this file to .env and customize as needed

# =============================================================================
# API Configuration
# =============================================================================

# Server host and port
API_HOST=0.0.0.0
API_PORT=8000

# Environment mode: development, production
ENVIRONMENT=development

# Enable/disable debug mode
DEBUG=true

# =============================================================================
# Model Configuration
# =============================================================================

# Model to use (HuggingFace model ID or local path)
MODEL_NAME=philschmid/flan-t5-base-samsum

# Device: auto, cpu, cuda
DEVICE=auto

# Enable FP16 (half precision) for faster inference on GPU
USE_FP16=true

# =============================================================================
# Generation Parameters
# =============================================================================

# Default max summary length
DEFAULT_MAX_LENGTH=128

# Default min summary length

DEFAULT_MIN_LENGTH=30

# Default number of beams for beam search
DEFAULT_NUM_BEAMS=4

# Default length penalty
DEFAULT_LENGTH_PENALTY=0.8

# =============================================================================
# Performance Settings
# =============================================================================

# Maximum batch size for batch endpoint
MAX_BATCH_SIZE=20

# Request timeout in seconds
REQUEST_TIMEOUT=60

# Enable model caching (singleton pattern)
ENABLE_MODEL_CACHE=true

# =============================================================================
# Logging Configuration
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Log file path
LOG_FILE=logs/running_logs.log

# =============================================================================
# CORS Settings (for frontend integration)
# =============================================================================

# Allowed origins (comma-separated, use * for all)
CORS_ORIGINS=*

# Allow credentials
CORS_CREDENTIALS=true

# =============================================================================
# Rate Limiting (optional, for production)
# =============================================================================

# Enable rate limiting
RATE_LIMIT_ENABLED=false

# Requests per minute per IP
RATE_LIMIT_RPM=60

# =============================================================================
# Training Configuration (if training locally)
# =============================================================================

# Training profile: zero_training, quick_test, laptop_friendly, full_training
TRAINING_PROFILE=zero_training

# HuggingFace token (for private models/datasets)
# HF_TOKEN=your_token_here
