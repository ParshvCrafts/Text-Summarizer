# Render Blueprint Configuration - FREE TIER OPTIMIZED
# Uses Hugging Face API for model inference (no memory limits!)

services:
  # Backend API Service (Free Tier - 512MB RAM)
  - type: web
    name: text-summarizer-api
    runtime: python
    region: oregon
    plan: free
    buildCommand: pip install requests fastapi uvicorn
    startCommand: uvicorn app_hf:app --host 0.0.0.0 --port $PORT
    healthCheckPath: /health
    envVars:
      - key: PYTHON_VERSION
        value: "3.11"
      - key: CORS_ORIGINS
        value: "*"
      # Optional: Add your Hugging Face token for higher rate limits
      # - key: HF_API_TOKEN
      #   value: "your_token_here"
    autoDeploy: true

  # Frontend Static Site (Free)
  - type: web
    name: text-summarizer-frontend
    runtime: static
    buildCommand: cd frontend && npm install && npm run build
    staticPublishPath: frontend/dist
    headers:
      - path: /*
        name: Cache-Control
        value: public, max-age=31536000
    routes:
      - type: rewrite
        source: /*
        destination: /index.html
    envVars:
      - key: VITE_API_URL
        value: https://text-summarizer-api.onrender.com
    autoDeploy: true
